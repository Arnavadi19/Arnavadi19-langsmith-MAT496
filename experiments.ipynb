{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the RAG Application that we've been working with throughout this course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "\n",
    "# TODO: Configure this model!\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def get_vector_db_retriever():\n",
    "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "    embd = OpenAIEmbeddings()\n",
    "\n",
    "    # If vector store exists, then load it\n",
    "    if os.path.exists(persist_path):\n",
    "        vectorstore = SKLearnVectorStore(\n",
    "            embedding=embd,\n",
    "            persist_path=persist_path,\n",
    "            serializer=\"parquet\"\n",
    "        )\n",
    "        return vectorstore.as_retriever(lambda_mult=0)\n",
    "\n",
    "    # Otherwise, index LangSmith documents and create new vector store\n",
    "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
    "    ls_docs = ls_docs_sitemap_loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(ls_docs)\n",
    "\n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=doc_splits,\n",
    "        embedding=embd,\n",
    "        persist_path=persist_path,\n",
    "        serializer=\"parquet\"\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore.as_retriever(lambda_mult=0)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\n",
    "        \"ls_provider\": MODEL_PROVIDER,\n",
    "        \"ls_model_name\": MODEL_NAME\n",
    "    }\n",
    ")\n",
    "def call_openai(messages: List[dict]) -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a code snippet that should look similar to what you see from the starter code!\n",
    "\n",
    "There are a few important components here.\n",
    "\n",
    "1. We have defined an Evaluator\n",
    "2. We pipe our dataset examples (dict) to the shape of input that our function `langsmith_rag` takes (str) using a target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnav/miniconda3/envs/llm/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-4o-f4f0b31f' at:\n",
      "https://smith.langchain.com/o/ca7e6c98-5676-4fe8-bb6b-29a3e184274c/datasets/fb493d5a-d09f-4e0d-bcbc-39338c0fc35c/compare?selectedSessions=f792d089-355a-4c1b-a4ee-39883853593b\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:34,  2.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I use LangSmith for both online and offlin...</td>\n",
       "      <td>Yes, LangSmith supports both online and offlin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports both online evaluation...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.558724</td>\n",
       "      <td>2cb6d061-0c7e-40b9-85be-ba643c233a1c</td>\n",
       "      <td>2596f4c4-8d90-4502-849f-a224110e1b5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key steps to enable tracing in La...</td>\n",
       "      <td>To enable tracing in LangChain applications, y...</td>\n",
       "      <td>None</td>\n",
       "      <td>The key steps are: 1) Set LANGSMITH_TRACING='t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054865</td>\n",
       "      <td>2e1864d5-4f91-478e-908a-dad2d86138db</td>\n",
       "      <td>6b6a2b3b-c598-4b2c-ab92-44c37f67c27d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain the @traceable decorator in one sentence.</td>\n",
       "      <td>The @traceable decorator in LangSmith allows d...</td>\n",
       "      <td>None</td>\n",
       "      <td>The @traceable decorator in Python automatical...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.905993</td>\n",
       "      <td>80ad6dbb-fdd2-4c72-a9d1-253c3ff61365</td>\n",
       "      <td>5452ad00-6b45-479e-9543-444cf1eba0b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>The provided context does not mention support ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.246679</td>\n",
       "      <td>270f18c5-db6a-4e58-88f1-f3917032fafe</td>\n",
       "      <td>ee4ed761-bda1-4f4a-b8af-1106fef3a704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is a platform designed for building ...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.661329</td>\n",
       "      <td>2e8d2309-80ba-4af0-95f9-ea9b1596520e</td>\n",
       "      <td>3aec4c18-4375-487b-bcee-bd26e817bbf3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation. It ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.251139</td>\n",
       "      <td>320d33c2-b7be-41b7-ba52-ac9e4a8ec8bc</td>\n",
       "      <td>cb7655c5-d990-455d-99b5-413fe8e075c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith using LangChain...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.305328</td>\n",
       "      <td>42824a0e-8898-4c2a-a842-45a5fbb8f2b0</td>\n",
       "      <td>90fc4756-9964-4d4d-a597-0cca5dfc3aee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>To pass metadata with the `@traceable` decorat...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.325927</td>\n",
       "      <td>84579025-7bde-49e7-9085-25d97168bf85</td>\n",
       "      <td>6c7aed00-12a5-4bbd-afd6-3fe4f7708997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.051026</td>\n",
       "      <td>91cd2f4e-dbd0-45dc-9a63-49a0289441c6</td>\n",
       "      <td>3711809b-334c-4612-a040-286dc931169f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is not designed for finetuning a...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.597399</td>\n",
       "      <td>b01f3125-6ef5-4b91-9c17-2f476e65cec2</td>\n",
       "      <td>17c0f0ef-2ccd-49fe-a4cd-652866997716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.922955</td>\n",
       "      <td>b7ae07c6-6180-4dd5-ad89-79b42661421f</td>\n",
       "      <td>1e735d89-7e93-4269-a7ed-cdcbffa43e39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>2.184836</td>\n",
       "      <td>bada531b-0778-4af0-a246-a87d2a168425</td>\n",
       "      <td>8d395452-b53d-4eb1-a748-1dcf546f8aba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith allows you to run multiple experimen...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.607967</td>\n",
       "      <td>c77940ad-d2b3-42b3-b587-c789c3aa792d</td>\n",
       "      <td>b10510f5-6d87-42c7-8842-cb6883d8d660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-4o-f4f0b31f>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"RAG-dataset-golden\"\n",
    "\n",
    "def is_concise_enough(reference_outputs: dict, outputs: dict) -> dict:\n",
    "    score = len(outputs[\"output\"]) < 1.5 * len(reference_outputs[\"output\"])\n",
    "    return {\"key\": \"is_concise\", \"score\": int(score)}\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying your Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's change our model to gpt-35-turbo and see how it performs!\n",
    "\n",
    "Make this change, and then run this code snippet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-3.5-turbo-4cc9edde' at:\n",
      "https://smith.langchain.com/o/ca7e6c98-5676-4fe8-bb6b-29a3e184274c/datasets/fb493d5a-d09f-4e0d-bcbc-39338c0fc35c/compare?selectedSessions=ab52e838-7541-47d5-84bc-ace4f17ad632\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:33,  2.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I use LangSmith for both online and offlin...</td>\n",
       "      <td>Yes, LangSmith supports both online and offlin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports both online evaluation...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.872414</td>\n",
       "      <td>2cb6d061-0c7e-40b9-85be-ba643c233a1c</td>\n",
       "      <td>0bf6e6fd-ed92-41ad-b816-74245bb37315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key steps to enable tracing in La...</td>\n",
       "      <td>To enable tracing in LangChain applications, y...</td>\n",
       "      <td>None</td>\n",
       "      <td>The key steps are: 1) Set LANGSMITH_TRACING='t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.801209</td>\n",
       "      <td>2e1864d5-4f91-478e-908a-dad2d86138db</td>\n",
       "      <td>3ebf59ac-57db-4a77-abbb-4f7566ba4d89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain the @traceable decorator in one sentence.</td>\n",
       "      <td>The @traceable decorator in Python is a simple...</td>\n",
       "      <td>None</td>\n",
       "      <td>The @traceable decorator in Python automatical...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.450568</td>\n",
       "      <td>80ad6dbb-fdd2-4c72-a9d1-253c3ff61365</td>\n",
       "      <td>872c185e-9054-4750-bb7f-32f9479989da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>The provided context does not mention offline ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.016589</td>\n",
       "      <td>270f18c5-db6a-4e58-88f1-f3917032fafe</td>\n",
       "      <td>b71e7bb6-bf2f-478f-9d0d-be619f5d232f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is a platform designed for building ...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.035991</td>\n",
       "      <td>2e8d2309-80ba-4af0-95f9-ea9b1596520e</td>\n",
       "      <td>4fec44ed-2bd8-47ca-be6d-83da0d2cc1f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation. It ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.616847</td>\n",
       "      <td>320d33c2-b7be-41b7-ba52-ac9e4a8ec8bc</td>\n",
       "      <td>4cac52b9-3316-47d7-9e6e-d2b8e6d15cfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith using LangChain...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.048633</td>\n",
       "      <td>42824a0e-8898-4c2a-a842-45a5fbb8f2b0</td>\n",
       "      <td>7d8296b6-4489-4730-8095-70659b492083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>You can pass metadata in with `@traceable` by ...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.990204</td>\n",
       "      <td>84579025-7bde-49e7-9085-25d97168bf85</td>\n",
       "      <td>2f9b3064-5f77-4c7d-b313-f656186cca94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.990294</td>\n",
       "      <td>91cd2f4e-dbd0-45dc-9a63-49a0289441c6</td>\n",
       "      <td>a1f0ed33-c546-4659-8e39-e57971d3a8a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>LangSmith is primarily designed for building, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.240987</td>\n",
       "      <td>b01f3125-6ef5-4b91-9c17-2f476e65cec2</td>\n",
       "      <td>c99a3e5e-503a-4d77-9963-d0a505575da4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.893846</td>\n",
       "      <td>b7ae07c6-6180-4dd5-ad89-79b42661421f</td>\n",
       "      <td>cee1e80c-60a5-4bfe-b0e2-4113db7865f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>2.305163</td>\n",
       "      <td>bada531b-0778-4af0-a246-a87d2a168425</td>\n",
       "      <td>21099d7f-61de-4b56-ad4f-4d0606e8ce13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith allows you to run multiple experimen...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.361354</td>\n",
       "      <td>c77940ad-d2b3-42b3-b587-c789c3aa792d</td>\n",
       "      <td>fa8520de-00b8-4bc7-a16a-8fcc62fcd9e2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-3.5-turbo-4cc9edde>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running over Different pieces of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Version\n",
    "\n",
    "You can execute an experiment on a specific version of a dataset in the sdk by using the `as_of` parameter in `list_examples`\n",
    "\n",
    "Let's try running on just our initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'initial dataset version-d820afeb' at:\n",
      "https://smith.langchain.com/o/ca7e6c98-5676-4fe8-bb6b-29a3e184274c/datasets/fb493d5a-d09f-4e0d-bcbc-39338c0fc35c/compare?selectedSessions=86a1e0fc-97a7-421c-8a01-8ba44a3fcd15\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:29,  2.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I use LangSmith for both online and offlin...</td>\n",
       "      <td>Yes, you can use LangSmith for both online and...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports both online evaluation...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.700763</td>\n",
       "      <td>2cb6d061-0c7e-40b9-85be-ba643c233a1c</td>\n",
       "      <td>45e411aa-a2b3-40b7-b07d-5008fd8ea1e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key steps to enable tracing in La...</td>\n",
       "      <td>To enable tracing in LangChain applications, y...</td>\n",
       "      <td>None</td>\n",
       "      <td>The key steps are: 1) Set LANGSMITH_TRACING='t...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.026411</td>\n",
       "      <td>2e1864d5-4f91-478e-908a-dad2d86138db</td>\n",
       "      <td>25260c14-e983-454b-a96e-b4d951999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain the @traceable decorator in one sentence.</td>\n",
       "      <td>The @traceable decorator in LangSmith's Python...</td>\n",
       "      <td>None</td>\n",
       "      <td>The @traceable decorator in Python automatical...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.606594</td>\n",
       "      <td>80ad6dbb-fdd2-4c72-a9d1-253c3ff61365</td>\n",
       "      <td>87618bc0-c20e-40f1-bbc4-530efcfa0d6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>The provided context does not mention LangSmit...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.148657</td>\n",
       "      <td>270f18c5-db6a-4e58-88f1-f3917032fafe</td>\n",
       "      <td>36015c02-fa18-4967-bc21-f403eb142e77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is a platform designed for building ...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.078051</td>\n",
       "      <td>2e8d2309-80ba-4af0-95f9-ea9b1596520e</td>\n",
       "      <td>72aa3779-8368-441b-9e06-37c4991157a8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation. It ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.263582</td>\n",
       "      <td>320d33c2-b7be-41b7-ba52-ac9e4a8ec8bc</td>\n",
       "      <td>00ef5079-a8cd-4a23-8774-c91440d3bed1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith when using Lang...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.421670</td>\n",
       "      <td>42824a0e-8898-4c2a-a842-45a5fbb8f2b0</td>\n",
       "      <td>5473fc19-e627-461b-9ca0-49839e9d35c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>To pass metadata with the `@traceable` decorat...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.872939</td>\n",
       "      <td>84579025-7bde-49e7-9085-25d97168bf85</td>\n",
       "      <td>817cae7d-22e1-4892-93ec-1e7c986c52f8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback using the LangSmith SD...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.650564</td>\n",
       "      <td>91cd2f4e-dbd0-45dc-9a63-49a0289441c6</td>\n",
       "      <td>48047e92-67c9-4c3f-96b8-a6aa44ce1846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is focused on observability, eva...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.711177</td>\n",
       "      <td>b01f3125-6ef5-4b91-9c17-2f476e65cec2</td>\n",
       "      <td>ee619fce-1181-4aeb-8fb4-0961ea7644e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the @traceable decorator, you ne...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.049319</td>\n",
       "      <td>b7ae07c6-6180-4dd5-ad89-79b42661421f</td>\n",
       "      <td>9c03b7c2-75eb-450a-a178-277cbf294d0a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.786939</td>\n",
       "      <td>bada531b-0778-4af0-a246-a87d2a168425</td>\n",
       "      <td>80e5f334-8967-4e98-ae8d-89fb9e206c2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith allows you to run multiple experimen...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.664684</td>\n",
       "      <td>c77940ad-d2b3-42b3-b587-c789c3aa792d</td>\n",
       "      <td>300ad5e7-15eb-4008-b770-d807464663d8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults initial dataset version-d820afeb>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(dataset_name=dataset_name),   \n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"initial dataset version\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Split\n",
    "\n",
    "You can run an experiment on a specific split of your dataset, let's try running on the Crucial Examples split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCrucial Examples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We pass in a list of Splits\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_concise_enough\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCrucial Examples split\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:418\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, **kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    417\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1060\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results)\u001b[39m\n\u001b[32m   1041\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1042\u001b[39m experiment_, runs = _resolve_experiment(\n\u001b[32m   1043\u001b[39m     experiment,\n\u001b[32m   1044\u001b[39m     runs,\n\u001b[32m   1045\u001b[39m     client,\n\u001b[32m   1046\u001b[39m )\n\u001b[32m   1048\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m cache_dir = ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1062\u001b[39m cache_path = (\n\u001b[32m   1063\u001b[39m     pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1064\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1432\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1434\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(dataset_name=dataset_name, splits=[\"Crucial Examples\"]),  # We pass in a list of Splits   \n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"Crucial Examples split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific Data Points\n",
    "\n",
    "You can specify individual data points to run an experiment over as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithError",
     "evalue": "Failed to GET /examples in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=fb493d5a-d09f-4e0d-bcbc-39338c0fc35c', '{\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=fb493d5a-d09f-4e0d-bcbc-39338c0fc35c",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/client.py:828\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    823\u001b[39m         method,\n\u001b[32m    824\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    825\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    826\u001b[39m         **request_kwargs,\n\u001b[32m    827\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=fb493d5a-d09f-4e0d-bcbc-39338c0fc35c] {\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# We pass in a specific list of example_ids\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO: You will need to paste in your own example ids for this to work!\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_concise_enough\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtwo specific example ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:418\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, **kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    417\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1060\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results)\u001b[39m\n\u001b[32m   1041\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1042\u001b[39m experiment_, runs = _resolve_experiment(\n\u001b[32m   1043\u001b[39m     experiment,\n\u001b[32m   1044\u001b[39m     runs,\n\u001b[32m   1045\u001b[39m     client,\n\u001b[32m   1046\u001b[39m )\n\u001b[32m   1048\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m cache_dir = ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1062\u001b[39m cache_path = (\n\u001b[32m   1063\u001b[39m     pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1064\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/evaluation/_runner.py:1432\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1434\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/client.py:4883\u001b[39m, in \u001b[36mClient.list_examples\u001b[39m\u001b[34m(self, dataset_id, dataset_name, example_ids, as_of, splits, inline_s3_urls, offset, limit, metadata, filter, include_attachments, **kwargs)\u001b[39m\n\u001b[32m   4881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_attachments:\n\u001b[32m   4882\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[33m\"\u001b[39m\u001b[33mattachment_urls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m4883\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   4884\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_paginated_list\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/examples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4885\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_convert_stored_attachments_to_attachments_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattachments_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattachment_urls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_url\u001b[49m\n\u001b[32m   4888\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4890\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mls_schemas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4891\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattachment_urls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4892\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4893\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_host_url\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_host_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4894\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_tenant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_optional_tenant_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4895\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/client.py:984\u001b[39m, in \u001b[36mClient._get_paginated_list\u001b[39m\u001b[34m(self, path, params)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    983\u001b[39m     params_[\u001b[33m\"\u001b[39m\u001b[33moffset\u001b[39m\u001b[33m\"\u001b[39m] = offset\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    989\u001b[39m     items = response.json()\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.13/site-packages/langsmith/client.py:877\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    873\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    874\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    875\u001b[39m         )\n\u001b[32m    876\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m877\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    878\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    879\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m         )\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    883\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithUserError(\n\u001b[32m    884\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    885\u001b[39m     )\n",
      "\u001b[31mLangSmithError\u001b[39m: Failed to GET /examples in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=fb493d5a-d09f-4e0d-bcbc-39338c0fc35c', '{\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}')"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(\n",
    "        dataset_name=dataset_name, \n",
    "        example_ids=[   # We pass in a specific list of example_ids\n",
    "            # TODO: You will need to paste in your own example ids for this to work!\n",
    "            \"\",\n",
    "            \"\"\n",
    "        ]\n",
    "    ),\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"two specific example ids\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repetitions\n",
    "\n",
    "You can run an experiment several times to make sure you have consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"two repetitions\",\n",
    "    num_repetitions=2   # This field defaults to 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concurrency\n",
    "You can also kick off concurrent threads of execution to make your experiments finish faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"concurrency\",\n",
    "    max_concurrency=3,  # This defaults to None, so this is an improvement!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metadata \n",
    "\n",
    "You can (and should) add metadata to your experiments, to make them easier to find in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"metadata added\",\n",
    "    metadata={  # We can pass custom metadata for the experiment, such as the model name\n",
    "        \"model_name\": MODEL_NAME\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
